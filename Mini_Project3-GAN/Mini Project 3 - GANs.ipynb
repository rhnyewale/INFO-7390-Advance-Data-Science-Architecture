{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs (Generative Adversarial Networks)\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Our objective is to learn how to implement Generative Adversarial Networks(GANs) using Keras and TensorFlow. We will be implementing on Fashion MNIST dataset.\n",
    "\n",
    "**Objective**\n",
    "1. Discuss Generative Adversarial Networks\n",
    "2. Implement GAN architecture using Keras and Tensorflow\n",
    "3. Train Fashion MNIST dataset\n",
    "4. Generate fake/synthetic apparel images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generative Adversarial Networks** can be used to generate synthetic (i.e., fake) images that are perceptually near identical to their ground-truth authentic originals.\n",
    "\n",
    "<Img src=\"https://github.com/rhnyewale/INFO-7390-Advance-Data-Science-Architecture/blob/master/Mini_Project3-GAN/Images/GANs.jpg?raw=true\">\n",
    "\n",
    "In order to generate synthetic images, we make use of two neural networks during training:\n",
    "\n",
    "1. A generator that accepts an input vector of randomly generated noise and produces an output “imitation” image that looks similar, if not identical, to the authentic image\n",
    "2. A discriminator or adversary that attempts to determine if a given image is an “authentic” or “fake”\n",
    "\n",
    "By training these networks at the same time, one giving feedback to the other, we can learn to generate synthetic images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General GAN training procedure\n",
    "\n",
    "<Img src=\"https://github.com/rhnyewale/INFO-7390-Advance-Data-Science-Architecture/blob/master/Mini_Project3-GAN/Images/GANs_Training%20.jpg?raw=true\">\n",
    "    \n",
    "    \n",
    "**Step 1** we randomly generate a vector (i.e., noise). We pass this noise through our generator,\n",
    "    \n",
    "**Step 2** which generates an actual image in **Step 2**\n",
    "    \n",
    "**Step 3** We then sample authentic images from our training set and mix them with our synthetic images\n",
    "\n",
    "**Step 4** next step is to train our discriminator using this mixed set. The goal of the discriminator is to correctly label each image as “real” or “fake.”\n",
    "\n",
    "**Step 5** Next, we’ll once again generate random noise, but this time we’ll purposely label each noise vector as a “real image” \n",
    "\n",
    "**Step 6** We’ll then train the GAN using the noise vectors and “real image” labels even though they are not actual real images\n",
    "    \n",
    "    \n",
    "**The reason this process works is due to the following:**\n",
    "\n",
    "1. We have frozen the weights of the discriminator at this stage, implying that the discriminator is not learning when we update the weights of the generator.\n",
    "    <br/><br/>\n",
    "2. We’re trying to “fool” the discriminator into being unable to determine which images are real vs. synthetic. The feedback from the discriminator will allow the generator to learn how to produce more authentic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.2.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (3.2.1)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.30.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (3.12.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.18.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.11.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (45.2.0.post20200210)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.18.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\rhnye\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.3.tar.gz (17 kB)\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.3-py3-none-any.whl size=25856 sha256=123664ff0e1e585427416b893f5d07bad40e7a2445bdb2fb0ccde3eaa61c3860\n",
      "  Stored in directory: c:\\users\\rhnye\\appdata\\local\\pip\\cache\\wheels\\fc\\9c\\6d\\1826267c72afa51b564c9c6e0f66abc806879338bc593a2270\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from imutils import build_montages\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Function to display images in Jupyter Notebooks and Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_imshow(title, image):\n",
    "  # convert the image frame BGR to RGB color space and display it\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image, aspect=\"auto\")\n",
    "    plt.title(title)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing our “generator” and “discriminator” with Keras and TensorFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    @staticmethod\n",
    "    def build_generator(dim, depth, channels=1, inputDim=100,\n",
    "        outputDim=512):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (dim, dim, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # first set of FC => RELU => BN layers\n",
    "        model.add(Dense(input_dim=inputDim, units=outputDim))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        # second set of FC => RELU => BN layers, this time preparing\n",
    "        # the number of FC nodes to be reshaped into a volume\n",
    "        model.add(Dense(dim * dim * depth))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "  \n",
    "        # reshape the output of the previous layer set, upsample +\n",
    "        # apply a transposed convolution, RELU, and BN\n",
    "        model.add(Reshape(inputShape))\n",
    "        model.add(Conv2DTranspose(32, (5, 5), strides=(2, 2),\n",
    "            padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "  \n",
    "        # apply another upsample and transposed convolution, but\n",
    "        # this time output the TANH activation\n",
    "        model.add(Conv2DTranspose(channels, (5, 5), strides=(2, 2),\n",
    "            padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        # return the generator model\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_discriminator(width, height, depth, alpha=0.2):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\"\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "\n",
    "        # first set of CONV => RELU layers\n",
    "        model.add(Conv2D(32, (5, 5), padding=\"same\", strides=(2, 2),\n",
    "            input_shape=inputShape))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "        # second set of CONV => RELU layers\n",
    "        model.add(Conv2D(64, (5, 5), padding=\"same\", strides=(2, 2)))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "        # sigmoid layer outputting a single value\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # return the discriminator model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing our GAN training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"output\": \"output\",\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the epochs and batch size in convenience variables, then\n",
    "# initialize our learning rate\n",
    "NUM_EPOCHS = args[\"epochs\"]\n",
    "BATCH_SIZE = args[\"batch_size\"]\n",
    "INIT_LR = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 3s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the Fashion MNIST dataset and stack the training and testing\n",
    "# data points so we have additional training data\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "((trainX, _), (testX, _)) = fashion_mnist.load_data()\n",
    "trainImages = np.concatenate([trainX, testX])\n",
    "\n",
    "# add in an extra dimension for the channel and scale the images\n",
    "# into the range [-1, 1] (which is the range of the tanh\n",
    "# function)\n",
    "trainImages = np.expand_dims(trainImages, axis=-1)\n",
    "trainImages = (trainImages.astype(\"float\") - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building generator...\n",
      "[INFO] building discriminator...\n"
     ]
    }
   ],
   "source": [
    "# build the generator\n",
    "print(\"[INFO] building generator...\")\n",
    "gen = DCGAN.build_generator(7, 64, channels=1)\n",
    "\n",
    "# build the discriminator\n",
    "print(\"[INFO] building discriminator...\")\n",
    "disc = DCGAN.build_discriminator(28, 28, 1)\n",
    "discOpt = Adam(lr=INIT_LR, beta_1=0.5, decay=INIT_LR / NUM_EPOCHS)\n",
    "disc.compile(loss=\"binary_crossentropy\", optimizer=discOpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation\n",
    "\n",
    "https://arxiv.org/abs/1511.06434<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License\n",
    "\n",
    "Copyright 2020 Rohan Subhash Yewale\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
